{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1200b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7f1e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup):\n",
    "\n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        title = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
    "        \n",
    "        # Inner NavigatableString Object\n",
    "        title_value = title.text\n",
    "\n",
    "        # Title as a string value\n",
    "        title_string = title_value.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        title_string = \"\"\n",
    "\n",
    "    return title_string\n",
    "\n",
    "def get_rating(soup):\n",
    "\n",
    "    try:\n",
    "        rating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        try:\n",
    "            rating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
    "        except:\n",
    "            rating = \"\"\t\n",
    "\n",
    "    return rating\n",
    "\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        review_count = \"\"\t\n",
    "\n",
    "    return review_count\n",
    "\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price = soup.find(\"span\", attr={'class': 'a-price-whole'}).string.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        price = \"\"\n",
    "        \n",
    "    return price\n",
    "        \n",
    "\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        available = soup.find(\"div\", attrs={'id':'availability'})\n",
    "        available = available.find(\"span\").string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        available = \"Not Available\"\t\n",
    "\n",
    "    return available\n",
    "\n",
    "def get_description(soup):\n",
    "    try:\n",
    "        description = soup.find(\"div\", attrs={'id':'description'})\n",
    "        description = description.find(\"span\").string.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        description = \"Not Provided\"\n",
    "        \n",
    "    return description\n",
    "\n",
    "def get_asin(soup):\n",
    "    try:\n",
    "        asin = soup.find('th', string='ASIN').find_next_sibling('td').string.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        asin = \"\"\n",
    "        \n",
    "    return asin\n",
    "\n",
    "def get_product_desc(soup):\n",
    "    try:\n",
    "        product_desc = soup.find('div', attrs={'id': 'productDescription'}).find('p')\n",
    "        product_desc = product_desc.find(\"span\").string.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        product_desc = \"\"\n",
    "    \n",
    "    return product_desc\n",
    "        \n",
    "def get_manufacturer(soup):\n",
    "    try:\n",
    "        manufacturer = soup.find('th', string='Manufacturer').find_next_sibling('td')\n",
    "        manufacturer = manufacturer.find(\"span\").string.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        manufacturer = \"\"\n",
    "        \n",
    "    return manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a3a7b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 45\u001b[0m\n\u001b[0;32m     41\u001b[0m     d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_desc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(get_product_desc(new_soup))\n\u001b[0;32m     42\u001b[0m     d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanufacturer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(get_manufacturer(new_soup))\n\u001b[1;32m---> 45\u001b[0m amazon_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(d)\n\u001b[0;32m     46\u001b[0m amazon_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m amazon_df \u001b[38;5;241m=\u001b[39m amazon_df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # add your user agent \n",
    "    HEADERS = ({'User-Agent':'', 'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "    # The webpage URL\n",
    "    URL = \"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_1\"\n",
    "\n",
    "    # HTTP Request\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "    # Soup Object containing all data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    # Fetch links as List of Tag Objects\n",
    "    links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
    "\n",
    "    # Store the links\n",
    "    links_list = []\n",
    "\n",
    "    # Loop for extracting links from Tag Objects\n",
    "    for link in links:\n",
    "            links_list.append(link.get('href'))\n",
    "\n",
    "    d = {\"title\":[], \"price\":[], \"rating\":[], \"reviews\":[],\"availability\":[], \"description\":[], \"asin\":[], \"product_desc\":[], \"manufacturer\":[]}\n",
    "    \n",
    "    # Loop for extracting product details from each link \n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get(\"https://www.amazon.com\" + link, headers=HEADERS)\n",
    "\n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "        # Function calls to display all necessary product information\n",
    "        d['title'].append(get_title(new_soup))\n",
    "        d['price'].append(get_price(new_soup))\n",
    "        d['rating'].append(get_rating(new_soup))\n",
    "        d['reviews'].append(get_review_count(new_soup))\n",
    "        d['availability'].append(get_availability(new_soup))\n",
    "        d['description'].append(get_description(new_soup))\n",
    "        d['asin'].append(get_asin(new_soup))\n",
    "        d['product_desc'].append(get_product_desc(new_soup))\n",
    "        d['manufacturer'].append(get_manufacturer(new_soup))\n",
    "        \n",
    "        \n",
    "    amazon_df = pd.DataFrame.from_dict(d)\n",
    "    amazon_df['title'].replace('', np.nan, inplace=True)\n",
    "    amazon_df = amazon_df.dropna(subset=['title'])\n",
    "    amazon_df.to_csv(\"amazon_data.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11909f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6de489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d38185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67402e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
